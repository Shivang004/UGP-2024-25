{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: .\\2011-2018-fall.json\n",
      "Processing file: .\\2011-2018-spring.json\n",
      "Processing file: .\\2019-fall-keywords.json\n",
      "Processing file: .\\2019-spring-keywords.json\n",
      "Processing file: .\\2022-spring-keywords.json\n",
      "Processing file: .\\keywords-fall-2021.json\n",
      "Processing file: .\\keywords-fall-2022.json\n",
      "Processing file: .\\keywords-fall-2023.json\n",
      "Processing file: .\\keywords-fall-2024.json\n",
      "Processing file: .\\keywords-spring-2021.json\n",
      "Processing file: .\\keywords-spring-2023.json\n",
      "Processing file: .\\keywords-spring-2024.json\n",
      "Processing file: .\\keywords-spring-fall-2020.json\n",
      "Total keywords combined: 559997\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def combine_json_files(root_folder, combined_json_file):\n",
    "    combined_data = []\n",
    "    count=0\n",
    "    for filename in os.listdir(root_folder):\n",
    "        if filename.endswith(\".json\") and filename != \"combined_for_param_tuning.json\":\n",
    "            file_path = os.path.join(root_folder, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    for entry in data:\n",
    "                        if \"year\" in entry and \"keywords\" in entry:\n",
    "                            combined_data.append({\n",
    "                                \"year\": entry[\"year\"],\n",
    "                                \"keywords\": entry[\"keywords\"]\n",
    "                            })\n",
    "                            count+=len(entry[\"keywords\"])\n",
    "                        else:\n",
    "                            print(f\"Skipping entry without 'year' or 'keywords': {entry}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON file: {filename}\")\n",
    "    print(f\"Total keywords combined: {count}\")\n",
    "    combined_data.sort(key=lambda x: x[\"year\"])\n",
    "    \n",
    "    with open(combined_json_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(combined_data, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "combine_json_files(\".\", \"combined.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "keywords = []\n",
    "with open(\"combined.json\", 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    for entry in data:\n",
    "        keywords.extend(entry[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Keywords = 559997\n",
      "Total Unique Keywords = 299751\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Keywords = {len(keywords)}\")\n",
    "print(f\"Total Unique Keywords = {len(set(keywords))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2011: 30173, 2012: 30084, 2013: 39489, 2014: 40820, 2015: 40915, 2016: 37426, 2017: 38293, 2018: 37697, 2019: 354, 2020: 13900, 2021: 24907, 2022: 14765, 2023: 30961, 2024: 30991}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "keywords = {}\n",
    "with open(\"combined.json\", 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    for year in range(2011,2025):\n",
    "        res=[]\n",
    "        for entry in data:\n",
    "            if entry[\"year\"] == year:\n",
    "                res.extend(entry[\"keywords\"])\n",
    "        keywords[year] = len(set(res))\n",
    "                \n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2011: 39460, 2012: 38593, 2013: 52649, 2014: 54313, 2015: 54100, 2016: 48723, 2017: 50367, 2018: 48579, 2019: 20951, 2020: 20982, 2021: 31768, 2022: 17980, 2023: 40522, 2024: 41010}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "keywords = {}\n",
    "with open(\"combined.json\", 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    for year in range(2011,2025):\n",
    "        res=[]\n",
    "        for entry in data:\n",
    "            if entry[\"year\"] == year:\n",
    "                res.extend(entry[\"keywords\"])\n",
    "        keywords[year] = len(res)\n",
    "                \n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26772\n",
      "21246\n"
     ]
    }
   ],
   "source": [
    "with open(\"2011-2018-fall.json\", 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    res=[]\n",
    "    for entry in data:\n",
    "        if entry[\"year\"] == 2011:\n",
    "            res.extend(entry[\"keywords\"])\n",
    "print(len(res))\n",
    "print(len(set(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688\n",
      "10649\n"
     ]
    }
   ],
   "source": [
    "with open(\"2011-2018-spring.json\", 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "    res=[]\n",
    "    for entry in data:\n",
    "        if entry[\"year\"] == 2011:\n",
    "            res.extend(entry[\"keywords\"])\n",
    "print(len(res))\n",
    "print(len(set(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh20_mindist0.025.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh20_mindist0.025.json: 690\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh20_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh20_mindist0.05.json: 737\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh20_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh20_mindist0.1.json: 829\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh20_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh20_mindist0.5.json: 1859\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh25_mindist0.0.025.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh25_mindist0.0.025.json: 679\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh25_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh25_mindist0.05.json: 713\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh25_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh25_mindist0.1.json: 825\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh25_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh25_mindist0.5.json: 1851\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh30_mindist0.025.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh30_mindist0.025.json: 659\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh30_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh30_mindist0.05.json: 700\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh30_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh30_mindist0.1.json: 798\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp20_nneigh30_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp20_nneigh30_mindist0.5.json: 1809\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh20_mindist0.025.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh20_mindist0.025.json: 683\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh20_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh20_mindist0.05.json: 735\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh20_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh20_mindist0.1.json: 833\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh20_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh20_mindist0.5.json: 1869\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh25_mindist0.025.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh25_mindist0.025.json: 675\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh25_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh25_mindist0.05.json: 726\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh25_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh25_mindist0.1.json: 822\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh25_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh25_mindist0.5.json: 1853\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh30_mindist0.025.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh30_mindist0.025.json: 660\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh30_mindist0.05.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh30_mindist0.05.json: 717\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh30_mindist0.1.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh30_mindist0.1.json: 804\n",
      "Processing file: ./Clusters_2011_Fall\\clustered_keywords_ncomp30_nneigh30_mindist0.5.json\n",
      "Total clusters in clustered_keywords_ncomp30_nneigh30_mindist0.5.json: 1798\n",
      "Total keywords combined: 24324\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def combine_json_files(root_folder):\n",
    "    count=0\n",
    "    for filename in os.listdir(root_folder):\n",
    "        count_clusterss=0\n",
    "        if filename.endswith(\".json\") and filename != \"combined_for_param_tuning.json\":\n",
    "            file_path = os.path.join(root_folder, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    for entry in data:\n",
    "                        count+=1\n",
    "                        count_clusterss+=1\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON file: {filename}\")\n",
    "        print(f\"Total clusters in {filename}: {count_clusterss}\")\n",
    "    print(f\"Total keywords combined: {count}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "combine_json_files(\"./Clusters_2011_Fall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"timeline_cluster_results/clusters_dt0.5.json\", 'r', encoding='utf-8') as file:\n",
    "    clusters = json.load(file)\n",
    "\n",
    "# Create a new dictionary with only the first keyword from each cluster\n",
    "keyword_to_years = {}\n",
    "for cluster_data in clusters.values():\n",
    "    keywords = cluster_data.get(\"keywords\", [])\n",
    "    years = cluster_data.get(\"years\", [])\n",
    "    if keywords:\n",
    "        keyword_to_years[keywords[0]] = sorted(list(set(years)))\n",
    "\n",
    "# Save the new JSON\n",
    "with open(\"cluster_representative_keywords.json\", \"w\") as f:\n",
    "    json.dump(keyword_to_years, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708\n",
      "1620\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"cluster_labels/2011_labeled_clusters.json\", 'r', encoding='utf-8') as file:\n",
    "    clusters = json.load(file)\n",
    "    print(len(clusters.values()))\n",
    "    print(len(set(clusters.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Representative keyword timeline saved to: ./timeline_cluster_results/representative_keyword_timeline.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# === Config ===\n",
    "INPUT_CLUSTER_FILE = \"clusters_dt0.5_with_year_counts.json\"  # Replace with your actual file path\n",
    "OUTPUT_FILE = \"./timeline_cluster_results/representative_keyword_timeline.json\"\n",
    "\n",
    "# === Load clustered data ===\n",
    "with open(INPUT_CLUSTER_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    cluster_data = json.load(f)\n",
    "\n",
    "# === Convert to representative keyword format ===\n",
    "representative_keywords = {}\n",
    "\n",
    "for cluster_id, cluster_info in cluster_data.items():\n",
    "    keywords = cluster_info.get(\"keywords\", [])\n",
    "    years = cluster_info.get(\"years\", {})\n",
    "    if keywords:\n",
    "        representative_keywords[keywords[0]] = years\n",
    "\n",
    "# === Save new JSON ===\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(representative_keywords, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Representative keyword timeline saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
